project: homecredit

provider: local

registry:
    registry_type: sql
    path: s3a://feast/registry.pb

offline_store:
    type: spark
    spark_conf:
        spark.master: "k8s://https://kubernetes.default.svc"
        spark.driver.extraClassPath: "/opt/spark/jars/*"
        spark.executor.extraClassPath: "/opt/spark/jars/*"
        spark.kubernetes.namespace: "feast"
        spark.kubernetes.container.image: "microwave1005/kfp-etl:feast-0.0.1"
        spark.kubernetes.authenticate.driver.serviceAccountName: "feast-homecredit"
        spark.kubernetes.authenticate.executor.serviceAccountName: "feast-homecredit"

        spark.driver.cores: "1"
        spark.driver.memory: "2g"

        spark.kubernetes.driver.request.cores: "500m"
        spark.kubernetes.driver.limit.cores: "1"
        spark.kubernetes.executor.request.cores: "500m"
        spark.kubernetes.executor.limit.cores: "1"
        spark.kubernetes.executor.request.memory: "1g"
        spark.kubernetes.executor.limit.memory: "2g"

        spark.executor.instances: "2"     
        spark.executor.cores: "1"
        spark.executor.memory: "2g"

        spark.ui.enabled: "false"
        spark.eventLog.enabled: "false"
        spark.sql.catalogImplementation: "hive"
        spark.sql.parser.quotedRegexColumnNames: "true"
        spark.sql.session.timeZone: "UTC"
        spark.sql.execution.arrow.fallback.enabled: "true"
        spark.sql.execution.arrow.pyspark.enabled: "true"

        spark.hadoop.fs.s3a.endpoint: "minio.minio.svc.cluster.local:9000"
        spark.hadoop.fs.s3a.impl: "org.apache.hadoop.fs.s3a.S3AFileSystem"
        spark.hadoop.fs.s3a.path.style.access: "true" 
        spark.hadoop.fs.s3a.connection.ssl.enabled: "false" 
        spark.hadoop.fs.s3a.access.key: "minio" 
        spark.hadoop.fs.s3a.secret.key: "minio123"  

        spark.hadoop.fs.s3a.connection.timeout: "60000"
        spark.hadoop.fs.s3a.socket.timeout: "60000"
        spark.hadoop.fs.s3a.attempts.maximum: "3"
        spark.hadoop.fs.s3a.connection.maximum: "100"
        spark.hadoop.fs.s3a.request.timeout: "60000"
        spark.hadoop.fs.s3a.idle.connection.time: "60000"
        spark.hadoop.fs.s3a.keep.alive: "true"

        spark.sql.extensions: "io.delta.sql.DeltaSparkSessionExtension"
        spark.sql.catalog.spark_catalog: "org.apache.spark.sql.delta.catalog.DeltaCatalog"
        spark.databricks.delta.schema.autoMerge.enabled: "true"

        hive.metastore.uris: "thrift://hive-metastore.database.svc.cluster.local:9083"

        spark.hadoop.fs.s3a.aws.credentials.provider: "org.apache.hadoop.fs.s3a.SimpleAWSCredentialsProvider"

online_store:
    type: redis
    redis_type: redis
    connection_string: "redis-master.database.svc.cluster.local:6379,password=huyduc2002"
    key_ttl_seconds: 86400 


entity_key_serialization_version: 3

auth:
    type: no_auth